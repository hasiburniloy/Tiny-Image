{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"mount_file_id":"1gHb-kFs6SbBFQrwsOepgJKUAoxHkhcYr","authorship_tag":"ABX9TyMyLBW2SDuNZJ119qSVsC/1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lNq3J9LUnONC","executionInfo":{"status":"ok","timestamp":1610448929581,"user_tz":-360,"elapsed":2391,"user":{"displayName":"Hasibur Niloy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrOy7UZEepaFHCBMMSM7oo8X9hfw2pEnRFziMqMA=s64","userId":"15985435121778949380"}}},"source":["## Importing library\r\n","import zipfile\r\n","import pandas as pd\r\n","import os\r\n","from shutil import copyfile\r\n","from os import getcwd\r\n","import numpy as np\r\n","import shutil\r\n","import random\r\n","import tensorflow as tf\r\n","from tensorflow.keras.optimizers import RMSprop\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"rpSBXUj5sGUT","executionInfo":{"status":"ok","timestamp":1610448942882,"user_tz":-360,"elapsed":945,"user":{"displayName":"Hasibur Niloy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrOy7UZEepaFHCBMMSM7oo8X9hfw2pEnRFziMqMA=s64","userId":"15985435121778949380"}}},"source":["#Helper function\r\n","#...............................................................................\r\n","#data extraction\r\n","def data_extract(zip_f_path,extract_path,Flag=False):\r\n","  #zip_f_path contain the zipfile location\r\n","  #extract_path contain the extracting location\r\n","  Extract=Flag\r\n","  if Extract:\r\n","    local_zip =zip_f_path \r\n","    zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n","    zip_ref.extractall(extract_path)\r\n","    zip_ref.close()\r\n","  else:\r\n","    print(\"File already downloaded\")\r\n","\r\n","#...............................................................................\r\n","\r\n","#Rename folder\r\n","def frenam(mapfilep, fpath):\r\n","    # mapfilep is the path of word file to map name\r\n","    # fpath is the path of the folder \r\n","   \r\n","    text = open(mapfilep, 'r')\r\n","    lines = text.readlines()\r\n","    names = {}\r\n","    \r\n","    for line in lines:\r\n","        k = line.split('\\t')[0]\r\n","        v = line.split('\\t')[1].split(',')[0].replace('\\n', '')\r\n","\r\n","        names[k] = v\r\n","    _dir = fpath\r\n","    folders = os.listdir(_dir)\r\n","    try:\r\n","        for fn in folders:\r\n","            if os.path.isdir(os.path.join(_dir, fn)):\r\n","                os.rename(os.path.join(_dir, fn), os.path.join(_dir, names[fn]))\r\n","        return print(\"Complete\")\r\n","    except:\r\n","        return print('Already done')\r\n","#...............................................................................\r\n","\r\n","#Validation set processing\r\n","\r\n","def val_process(source, dest, txtfpath):\r\n","    ## making dataframe to group file name based on label of folder\r\n","    import pandas as pd\r\n","    df = pd.read_csv(txtfpath, sep=\" \", header=None)\r\n","    for i in range(10000):\r\n","        df.loc[i, 'val1'] = df.iloc[i, 0].split(\"\\t\")[0]\r\n","        df.loc[i, 'val2'] = df.iloc[i, 0].split(\"\\t\")[1]\r\n","    a = df.drop([0], axis=1).groupby(['val2', 'val1']).size().to_frame()\r\n","\r\n","    ##Converting df to dictionary\r\n","    dic = {}\r\n","    li = []\r\n","    for i in range(len(a.index)):\r\n","        if i == len(a.index) - 1:\r\n","            li.append(a.index[i][1])\r\n","            dic[a.index[i][0]] = li\r\n","        else:\r\n","            if a.index[i][0] == a.index[i + 1][0]:\r\n","                li.append(a.index[i][1])\r\n","            else:\r\n","                li.append(a.index[i][1])\r\n","                dic[a.index[i][0]] = li\r\n","                li = []\r\n","    ##making path for destination\r\n","    if os.path.exists(dest):\r\n","        print(\"May be your file already processed,if not then delete the folder\")\r\n","\r\n","\r\n","    else:\r\n","        os.mkdir(dest)\r\n","        ##copying file from source to destination\r\n","        for k, l in dic.items():\r\n","\r\n","            try:\r\n","                shutil.rmtree(dest + k + '/')\r\n","                os.mkdir(dest + k + '/')\r\n","                file = l\r\n","                for li_valu in file:\r\n","\r\n","                    for f in os.listdir(source):\r\n","\r\n","                        if li_valu == f:\r\n","                            desfile = dest + k + '/' + f\r\n","                            thisfile = source + f\r\n","                            copyfile(thisfile, desfile)\r\n","\r\n","            except:\r\n","\r\n","                os.mkdir(dest + k + '/')\r\n","                file = l\r\n","                for li_valu in file:\r\n","\r\n","                    for f in os.listdir(source):\r\n","\r\n","                        if li_valu == f:\r\n","                            desfile = dest + k + '/' + f\r\n","                            thisfile = source + '/' + f\r\n","                            copyfile(thisfile, desfile)\r\n","\r\n","        print(\"Completed\")\r\n","#...............................................................................\r\n","\r\n","# Mdodel building\r\n","def tiny_model(epoch,tbatch,vbatch,trainpath,valpath):\r\n","  #epoch is the number of iteration\r\n","  #tbatch train batch size\r\n","  #vbatch validation batch size\r\n","  #trainpath training data path\r\n","  #valpath validation data path\r\n","  #\r\n","  #model \r\n","  model = tf.keras.models.Sequential([\r\n","    tf.keras.layers.Conv2D(64,(3,3), input_shape=(64, 64, 3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    tf.keras.layers.Conv2D(256,(3, 3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    \r\n","    tf.keras.layers.Flatten(),\r\n","    \r\n","    tf.keras.layers.Dense(512, activation='relu'),\r\n","    \r\n","    tf.keras.layers.Dense(256, activation='relu'),\r\n","    tf.keras.layers.Dense(256, activation='relu'),\r\n","    tf.keras.layers.Dense(200, activation='softmax')\r\n","  ])\r\n","  model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['acc'])\r\n","  \r\n","  # label generation \r\n","  TRAINING_DIR = trainpath\r\n","  train_datagen = ImageDataGenerator(\r\n","      rescale=1 / 255,\r\n","  )\r\n","  train_generator = train_datagen.flow_from_directory(\r\n","      TRAINING_DIR,\r\n","      batch_size=tbatch,\r\n","      class_mode='categorical',\r\n","      target_size=(64, 64)\r\n","        )\r\n","\r\n","  VALIDATION_DIR =valpath\r\n","  validation_datagen = ImageDataGenerator(\r\n","       rescale=1 / 255\r\n","  )\r\n","  validation_generator = validation_datagen.flow_from_directory(\r\n","      VALIDATION_DIR,\r\n","      batch_size=vbatch,\r\n","      class_mode='categorical',\r\n","      target_size=(64,64)\r\n","  )\r\n","  model.summary()\r\n","  history = model.fit_generator(train_generator,\r\n","                              epochs=epoch,\r\n","                              verbose=1,steps_per_epoch=100000/tbatch,\r\n","                              validation_data=validation_generator)\r\n","  return history\r\n","#.............................................................................."],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPpREMGZR_1A"},"source":["#extracting data\r\n","zip_f_path='/content/drive/MyDrive/task/archive.zip'\r\n","extract_path='/content/drive/MyDrive/task/dataset'\r\n","data_extract(zip_f_path,extract_path,Flag=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKeVOmZBtozw","executionInfo":{"status":"ok","timestamp":1610448949047,"user_tz":-360,"elapsed":4821,"user":{"displayName":"Hasibur Niloy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhrOy7UZEepaFHCBMMSM7oo8X9hfw2pEnRFziMqMA=s64","userId":"15985435121778949380"}},"outputId":"bdadc98f-2bb0-4050-9b13-c859fa7304ac"},"source":["#train folder process\r\n","mp=\"/content/drive/MyDrive/task/dataset/tiny-imagenet-200/tiny-imagenet-200/words.txt\"\r\n","fpath=\"/content/drive/MyDrive/task/dataset/tiny-imagenet-200/train/\"\r\n","frenam(mp,fpath)\r\n","#validation folder process \r\n","vsource='/content/drive/MyDrive/task/dataset/tiny-imagenet-200/val/images/'\r\n","dest='/content/drive/MyDrive/task/dataset/tiny-imagenet-200/newval/'\r\n","txtfpath='/content/drive/MyDrive/task/dataset/tiny-imagenet-200/tiny-imagenet-200/val/val_annotations.txt'\r\n","val_process(vsource,dest,txtfpath)\r\n","##validation rename folder\r\n","\r\n","fpath=dest\r\n","frenam(mp,fpath) "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Already done\n","May be your file already processed,if not then delet the new folder()\n","Already done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AB4qeuZ9LRbk","outputId":"55834ac6-f49d-4e79-da36-151c3f71b17a"},"source":["#Training model\r\n","epoch=60\r\n","tbatch=64\r\n","vbatch=32\r\n","trainpath='/content/drive/MyDrive/task/dataset/tiny-imagenet-200/train'\r\n","valpath=\"/content/drive/MyDrive/task/dataset/tiny-imagenet-200/newval\"\r\n","\r\n","history=tiny_model(epoch,tbatch,vbatch,trainpath,valpath)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 100000 images belonging to 200 classes.\n","Found 10000 images belonging to 200 classes.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 62, 62, 64)        1792      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 29, 29, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 12, 12, 256)       295168    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 4, 4, 256)         590080    \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1024)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               524800    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 200)               51400     \n","=================================================================\n","Total params: 1,734,216\n","Trainable params: 1,734,216\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/60\n","1562/1562 [==============================] - 156s 98ms/step - loss: 5.1178 - acc: 0.0169 - val_loss: 4.4030 - val_acc: 0.0792\n","Epoch 2/60\n","1562/1562 [==============================] - 152s 98ms/step - loss: 4.3008 - acc: 0.0956 - val_loss: 3.9171 - val_acc: 0.1543\n","Epoch 3/60\n","1562/1562 [==============================] - 151s 97ms/step - loss: 3.8256 - acc: 0.1641 - val_loss: 3.6185 - val_acc: 0.1957\n","Epoch 4/60\n","1562/1562 [==============================] - 150s 96ms/step - loss: 3.5085 - acc: 0.2141 - val_loss: 3.6148 - val_acc: 0.2053\n","Epoch 5/60\n","1562/1562 [==============================] - 151s 97ms/step - loss: 3.3016 - acc: 0.2502 - val_loss: 3.7123 - val_acc: 0.2040\n","Epoch 6/60\n","1562/1562 [==============================] - 151s 97ms/step - loss: 3.1472 - acc: 0.2782 - val_loss: 3.5848 - val_acc: 0.2297\n","Epoch 7/60\n","1562/1562 [==============================] - 151s 96ms/step - loss: 3.0183 - acc: 0.3000 - val_loss: 3.5258 - val_acc: 0.2416\n","Epoch 8/60\n","1562/1562 [==============================] - 151s 97ms/step - loss: 2.9266 - acc: 0.3181 - val_loss: 3.5682 - val_acc: 0.2265\n","Epoch 9/60\n","1562/1562 [==============================] - 151s 96ms/step - loss: 2.8450 - acc: 0.3305 - val_loss: 3.6710 - val_acc: 0.2353\n","Epoch 10/60\n","1562/1562 [==============================] - 151s 97ms/step - loss: 2.7732 - acc: 0.3429 - val_loss: 3.5382 - val_acc: 0.2359\n","Epoch 11/60\n","1562/1562 [==============================] - 151s 96ms/step - loss: 2.7104 - acc: 0.3570 - val_loss: 3.7227 - val_acc: 0.2340\n","Epoch 12/60\n","1562/1562 [==============================] - 151s 96ms/step - loss: 2.6618 - acc: 0.3683 - val_loss: 3.8566 - val_acc: 0.2423\n","Epoch 13/60\n","1562/1562 [==============================] - 152s 97ms/step - loss: 2.6202 - acc: 0.3753 - val_loss: 4.0830 - val_acc: 0.2307\n","Epoch 14/60\n","1562/1562 [==============================] - 152s 97ms/step - loss: 2.5685 - acc: 0.3856 - val_loss: 3.8104 - val_acc: 0.2243\n","Epoch 15/60\n","1562/1562 [==============================] - 152s 97ms/step - loss: 2.5167 - acc: 0.3948 - val_loss: 3.9157 - val_acc: 0.2197\n","Epoch 16/60\n","1562/1562 [==============================] - 152s 97ms/step - loss: 2.4942 - acc: 0.4005 - val_loss: 4.4037 - val_acc: 0.2277\n","Epoch 17/60\n"," 487/1562 [========>.....................] - ETA: 1:35 - loss: 2.3985 - acc: 0.4204"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w7Y-6PNMwLEK"},"source":["%matplotlib inline\r\n","\r\n","import matplotlib.image  as mpimg\r\n","import matplotlib.pyplot as plt\r\n","\r\n","#-----------------------------------------------------------\r\n","# Retrieve a list of list results on training and test data\r\n","# sets for each training epoch\r\n","#-----------------------------------------------------------\r\n","acc=history.history['acc']\r\n","val_acc=history.history['val_acc']\r\n","loss=history.history['loss']\r\n","val_loss=history.history['val_loss']\r\n","\r\n","epochs=range(len(acc)) # Get number of epochs\r\n","\r\n","#------------------------------------------------\r\n","# Plot training and validation accuracy per epoch\r\n","#------------------------------------------------\r\n","plt.plot(epochs, acc, 'r', \"Training Accuracy\")\r\n","plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\r\n","plt.title('Training and validation accuracy')\r\n","plt.figure()\r\n","\r\n","#------------------------------------------------\r\n","# Plot training and validation loss per epoch\r\n","#------------------------------------------------\r\n","plt.plot(epochs, loss, 'r', \"Training Loss\")\r\n","plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\r\n","\r\n","\r\n","plt.title('Training and validation loss')"],"execution_count":null,"outputs":[]}]}